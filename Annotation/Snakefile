#!/usr/bin/env python3

import os
#run: snakemake --cores 64 --keep-incomplete --wait-for-files --rerun-incomplete --latency-wait 100 --nt
slurm=" --account=mchaisso_100 --time 50:00:00 --partition=qcb "
RefCHM13 = "/project/mchaisso_100/cmb-16/walfred/database/chm13knowngenes.bed"
RefGenes = "/project/mchaisso_100/cmb-16/walfred/database/gencode.v38_37_29_fix.gff3"
HG38 = "/project/mchaisso_100/cmb-16/walfred/database/hg38_full.fa"
CHM13 = "/project/mchaisso_100/cmb-16/walfred/database/GCF_009914755.1_T2T-CHM13v2.0_genomic.fa"
BOTHREF = "/project/mchaisso_100/cmb-16/walfred/database/hg38_chm13.fa"
QueryPath = "../query_pathes.txt"
hprcfitler = "../hprc_error.bed"
hprccramfile = "../hprc_depth.txt"
ScriptFolder = "/project/mchaisso_100/cmb-16/walfred/projects/CTGor/newrun/scripts/"
SaveFolder = "Groups/"
AlignmentsFolder = "../firstrun/newGeneCopies/"
nthreads = 32
AnchorSize = 1000
kmertype = 31


queries = {"CHM13_h1": CHM13, "HG38_h1":HG38}
with open(QueryPath, mode = 'r') as f:
        for line in f:
                line = line.split()
                queries[line[0]] = line[1]

wksamples = list(queries.keys())

with open(hprccramfile, mode = 'r') as f:
        hprccrams = [x.split()[0].split("/")[-1].split(".")[0] for x in f.read().splitlines()]


allprefixes = [SaveFolder+file[:-len("_annotate.fa")] for file in os.listdir(SaveFolder) if file.endswith( "_annotate.fa")  ]
#allprefixes =  [SaveFolder+"AMY_group1_AMY1AOOOAMY1BOOOAMY1C.fasta"]
rule all:
        input:  
                infile  = [ancient(prefix+"_annotate.fa") for prefix in allprefixes],
                infofile  = [ancient(prefix+"_filter.fa_info") for prefix in allprefixes],

                refmatch = [ancient(prefix+"_annotate.fa_refmatch") for prefix in allprefixes],

                novels  = [ancient(prefix+"_annotate.fa_novel.fa") for prefix in allprefixes],
                anchorfiles = [ancient(prefix+"_annotate.fa_anchor100000.fa") for prefix in allprefixes],
                blastfiles = [ancient(prefix+"_annotate.fa_blastn.out") for prefix in allprefixes],
                locations = [ancient(prefix+"_annotate.fa_location") for prefix in allprefixes],
                rawloc = [ancient(prefix+"_annotate.fa_rawloc.txt") for prefix in allprefixes],
                precloc =  [ ancient(prefix+"_annotate.fa_prelocs.txt")  for prefix in allprefixes  ],
                liftoveralignschecker = [ancient(prefix + "_annotate.fa_liftoveralignschecker") for prefix in allprefixes],
                liftover =  [ ancient(prefix+"_annotate.fa_liftover.txt")  for prefix in allprefixes  ],

                uncertains  = [ancient(prefix+"_uncertain.fa") for prefix in allprefixes],
                anchorfiles2 = [ancient(prefix+"_uncertain.fa_anchor100000.fa") for prefix in allprefixes],
                blastfiles2 = [ancient(prefix+"_uncertain.fa_blastn.out") for prefix in allprefixes],
                locations2 = [ancient(prefix+"_uncertain.fa_location") for prefix in allprefixes],
                rawloc2 = [ancient(prefix+"_uncertain.fa_rawloc.txt") for prefix in allprefixes],
                liftoveralignschecker2 = [ancient(prefix + "_uncertain.fa_liftoveralignschecker") for prefix in allprefixes],
                precloc2 =  [ ancient(prefix+"_uncertain.fa_prelocs.txt")  for prefix in allprefixes  ],
                liftover2 =  [ ancient(prefix+"_uncertain.fa_liftover.txt")  for prefix in allprefixes  ],


                globalalignschecker = [ancient(prefix + "_annotate.fa_globalalignschecker") for prefix in allprefixes],
                svcallings = [ancient(prefix+"_annotate.fa_svcall.tsv") for prefix in allprefixes  ],
                svcallings2  =  [ ancient(prefix+"_annotate.fa_svcall2.tsv")  for prefix in allprefixes  ],
                svcallingsuniq = [ancient(prefix+"_annotate.fa_svcalluniq.tsv") for prefix in allprefixes  ],
                svcallingsuniq2  =  [ ancient(prefix+"_annotate.fa_svcalluniq2.tsv")  for prefix in allprefixes  ],

                #treefromMSA = [ancient(prefix+"_annotate.fa_msa.fa") for prefix in allprefixes  ],
                genecounts = [ancient(prefix+"_annotate.fa_genecounts.tsv") for prefix in allprefixes  ],

                exonfound = [ancient(prefix+"_annotate.fa_exons.tsv") for prefix in allprefixes  ],


                #typefile = [ancient(prefix+"_annotate.fa_types.txt") for prefix in allprefixes],
                #typeannotates = [ancient(prefix+"_annotate.fa_typeannotate.txt") for prefix in allprefixes  ],

                summaries = [ancient(prefix+"_annotate.fa_annotatesummary.txt") for prefix in allprefixes  ],
                #summariesfix = [ancient(prefix+"_annotate.fa_annotatefix.txt") for prefix in allprefixes  ],
                #summariesfixed = [ancient(prefix+"_annotate.fa_annotatesummaryfix.txt") for prefix in allprefixes  ],

#Inital annotate

rule refmatch:
        input:  
                anchorfile = "{prefix}_annotate.fa",
                infofile = "{prefix}_filter.fa_info",
        params: 
                qpath = QueryPath,
                script = ScriptFolder,
                hg38 = HG38
        resources:
                mem_mb=10000,
                slurm_extra="--mem=10G -c 1 "
        threads: 1
        output:
                refmatch = "{prefix}_annotate.fa_refmatch",
        run:
                run = 1
                if run:
                        shell (" python {params.script}/RefMatch.py -i {input.anchorfile} -o {output.refmatch} ")   


#liftover begin
rule getnovel:
        input:
                groupfile = "{prefix}_annotate.fa",
                refmatch = ancient("{prefix}_annotate.fa_refmatch"),
        params:
                script = ScriptFolder,
        resources:
                mem_mb=2000,
                slurm_extra="--mem=2G -c 1 "
        threads: 1
        output:
                filterfile = "{prefix}_annotate.fa_novel.fa",
        run:
                run = 1
                shell("touch {output.filterfile} || true")
                shell("touch {wildcards.prefix}_liftoverlist || true")
                if run:
                        shell ("cat {input.refmatch} | grep -w Novel > {wildcards.prefix}_liftoverlist || true")
                        shell ("python {params.script}/getsequences.py -i {input.groupfile} -o {output.filterfile} -l {wildcards.prefix}_liftoverlist  ")

#liftover begin 
rule getuncertain:
        input:
                groupfile = "{prefix}_annotate.fa",
                refmatch = ancient("{prefix}_annotate.fa_refmatch"),
        params:
                script = ScriptFolder,
        resources:
                mem_mb=2000,
                slurm_extra="--mem=2G -c 1 "
        threads: 1
        output:
                filterfile = "{prefix}_uncertain.fa",
        run:
                run = 1
                import collections as cl
                listfile = wildcards.prefix + "_uncertainlist"
                shell("touch {output.filterfile} || true")
                shell("touch {listfile} || true")

                if run:
                        haplotorefs = cl.defaultdict(list)
                        selects = set()
                        lastname = ""
                        with open(input.refmatch, mode = 'r') as f:
                                for line in f:
                                        line = line.strip().split()
                                        name = line[0]
                                        if name == lastname:
                                                selects.add(lastname)
                                                selects.add(name)
                                        lastname = name

                                        haplo = "_".join(name.split('_')[2:-1])
                                        ref = line[1]
                                        diff = float(line[-2])

                                        if "_h" in haplo or "NC_0609" in haplo:
                                                if (haplo,ref) in haplotorefs:
                                                        selects.add( name )
                                                        selects.update(haplotorefs[(haplo,ref)])
                                                        haplotorefs[(haplo,ref)] = []
                                                else:
                                                        if diff > 0.1:
                                                                selects.add( name )

                                                        haplotorefs[(haplo,ref)].append(name)
                        if len(selects):

                                with open(listfile, mode = 'w') as f:
                                        f.write("\n".join(list(selects))+"\n")

                                shell ("python {params.script}/getsequences.py -i {input.groupfile} -o {output.filterfile} -l {listfile} ")



rule largeanchors:
        input:
                filterfile = ancient("{prefix}_annotate.fa_novel.fa"),
        params:
                qpath = QueryPath,
                script = ScriptFolder,
                hg38 = HG38,
                chm13 = CHM13
        resources:
                mem_mb=2000,
                slurm_extra="--mem=2G -c 1 "
        threads: 1
        output:
                anchorfile = "{prefix}_annotate.fa_anchor100000.fa",
        run:
                shell("touch {output.anchorfile} || true")
                run = 0
                if os.path.isfile(input.filterfile) and os.stat(input.filterfile).st_size > 10:
                        run = 1
                if run:
                        shell ("python {params.script}/addanchors.py -i {input.filterfile} -q {params.qpath} -o {output.anchorfile} -r {params.hg38},{params.chm13}" )

rule largeanchors2:
        input:
                filterfile = ancient("{prefix}_uncertain.fa"),
        params:
                qpath = QueryPath,
                script = ScriptFolder,
                hg38 = HG38,
                chm13 = CHM13
        resources:
                mem_mb=2000,
                slurm_extra="--mem=2G -c 1 "
        threads: 1
        output:
                anchorfile = "{prefix}_uncertain.fa_anchor100000.fa",
        run:
                shell("touch {output.anchorfile} || true")
                run = 0
                if os.path.isfile(input.filterfile) and os.stat(input.filterfile).st_size > 10:
                        run = 1
                if run:
                        shell ("python {params.script}/addanchors.py -i {input.filterfile} -q {params.qpath} -o {output.anchorfile} -r {params.hg38},{params.chm13}" )

rule blastn:
        input:
                anchorfile = ancient("{prefix}_annotate.fa_anchor100000.fa"),
        params:
                qpath = QueryPath,
                script = ScriptFolder,
                hg38 = HG38,
                chm13 = CHM13,
                bothref = BOTHREF,
        resources:
                mem_mb=128000,
                slurm_extra="--mem=128G -c 64 "
        threads: 64
        output:
                blastn = "{prefix}_annotate.fa_blastn.out",
        run:
                shell("touch {output.blastn} || true")
                run = 0
                if os.path.isfile(input.anchorfile) and os.stat(input.anchorfile).st_size > 10:
                        run = 1
                if run:
                        shell (" bash {params.script}/runblastmega.sh {input.anchorfile} {params.bothref}_db_mask {threads} 500 > {output.blastn}  ")
                        shell (" python {params.script}/BlastNamefix.py -i  {output.blastn} -q  {input.anchorfile} ")

rule blastn2:
        input:
                anchorfile = ancient("{prefix}_uncertain.fa_anchor100000.fa"),
        params:
                qpath = QueryPath,
                script = ScriptFolder,
                hg38 = HG38,
                chm13 = CHM13,
                bothref = BOTHREF,
        resources:
                mem_mb=32000,
                slurm_extra="--mem=32G -c 16 "
        threads: 64
        output:
                blastn = "{prefix}_uncertain.fa_blastn.out",
        run:
                shell("touch {output.blastn} || true")
                run = 0
                if os.path.isfile(input.anchorfile) and os.stat(input.anchorfile).st_size > 10:
                        run = 1
                if run:
                        shell (" bash {params.script}/runblastmega.sh {input.anchorfile} {params.bothref}_db_mask {threads} 500 > {output.blastn}  ")
                        shell (" python {params.script}/BlastNamefix.py -i  {output.blastn} -q  {input.anchorfile} ")


rule locate:
        input:
                anchorfile = ancient("{prefix}_annotate.fa_anchor100000.fa"),
                blastn = ancient("{prefix}_annotate.fa_blastn.out"),
        params:
                qpath = QueryPath,
                script = ScriptFolder,
                hg38 = HG38,
                chm13 = CHM13,
                bothref = BOTHREF,
        resources:
                mem_mb=100000,
                slurm_extra="--mem=100G -c 50 "
        threads: 50
        output: 
                location = "{prefix}_annotate.fa_location",
        run:
                shell("touch {output.location} || true")
                run = 0
                if os.path.isfile(input.anchorfile) and os.stat(input.anchorfile).st_size > 10:
                        run = 1
                if run:
                        shell ("python {params.script}/blastnmap.py -i {input.blastn} -r {params.bothref} -q {input.anchorfile} -o {output.location} -t {threads}")

rule locate2:
        input:
                anchorfile = ancient("{prefix}_uncertain.fa_anchor100000.fa"),
                blastn = ancient("{prefix}_uncertain.fa_blastn.out"),
        params:
                qpath = QueryPath,
                script = ScriptFolder,
                hg38 = HG38,
                chm13 = CHM13,
                bothref = BOTHREF,
        resources:
                mem_mb=100000,
                slurm_extra="--mem=100G -c 50 "
        threads: 50
        output: 
                location = "{prefix}_uncertain.fa_location",
        run:
                shell("touch {output.location} || true")
                run = 0
                if os.path.isfile(input.anchorfile) and os.stat(input.anchorfile).st_size > 10:
                        run = 1
                if run:
                        shell ("python {params.script}/blastnmap.py -i {input.blastn} -r {params.bothref} -q {input.anchorfile} -o {output.location} -t {threads}")


rule getrawlocation:
        input:  
                anchorfile = ancient("{prefix}_annotate.fa_anchor100000.fa"),
                location = ancient("{prefix}_annotate.fa_location"),
        params: 
                qpath = QueryPath,
                script = ScriptFolder,
                bothref = BOTHREF,
                hg38 = HG38,
                chm13 = CHM13,
        resources:  
                mem_mb=2000,
                slurm_extra="--mem=2G -c 1"
        threads: 1
        output: 
                rawloc="{prefix}_annotate.fa_rawloc.txt",
        run:
                shell("touch {output.rawloc} || true")
                run = 0
                if os.path.isfile(input.anchorfile) and os.stat(input.anchorfile).st_size > 10:
                        run = 1
                if run:
                        shell("python {params.script}/getbestrawloc.py -i {input.location}  -o {output.rawloc} -q {input.anchorfile} ")

rule getrawlocation2:
        input:  
                anchorfile = ancient("{prefix}_uncertain.fa_anchor100000.fa"),
                location = ancient("{prefix}_uncertain.fa_location"),
        params: 
                qpath = QueryPath,
                script = ScriptFolder,
                bothref = BOTHREF,
                hg38 = HG38,
                chm13 = CHM13,
        resources:  
                mem_mb=2000,
                slurm_extra="--mem=2G -c 1"
        threads: 1
        output: 
                rawloc="{prefix}_uncertain.fa_rawloc.txt",
        run:
                shell("touch {output.rawloc} || true")
                run = 0
                if os.path.isfile(input.anchorfile) and os.stat(input.anchorfile).st_size > 10:
                        run = 1
                if run:
                        shell("python {params.script}/getbestrawloc.py -i {input.location}  -o {output.rawloc} -q {input.anchorfile} ")



rule precisealign:
        input:  
                rawloc=ancient("{prefix}_annotate.fa_rawloc.txt"),
        params: 
                qpath = QueryPath,
                script = ScriptFolder,
                bothref = BOTHREF,
                hg38 = HG38,
                chm13 = CHM13,
        resources:  
                mem_mb=16000,
                slurm_extra="--mem=16G -c 8"
        threads: 8
        output: 
                globalalignschecker="{prefix}_annotate.fa_liftoveralignschecker",
        run:
                shell("touch {} || true".format(output.globalalignschecker))
                run = 0
                if os.path.isfile(input.rawloc) and os.stat(input.rawloc).st_size > 10:
                        run = 1
                if run:
                        folder = "{}_liftover/".format(wildcards.prefix.split("_group")[0] + "_group" + wildcards.prefix.split("_group")[1].split("_")[0])
                        shell("mkdir {} || true".format(folder))

                        stdflag = {"+":"",'-':"-i"}

                        shell ("rm {wildcards.prefix}_stretcherfiles || true")

                        shell ("touch {wildcards.prefix}_stretcherfiles || true")

                        runsize = 0
                        with open(input.rawloc, mode = 'r') as f:

                                table = sorted(f.readlines(), key = lambda x: int(x.split()[-2]) if len(x) else 0, reverse = 1)

                        if len(table):
                                for line in table:

                                        if len(line) == 0:
                                                continue

                                        line = line.split()

                                        name,q_c,q_s,q_e,q_t,r_c,r_s,r_e,r_t = line[:9]

                                        out_q = folder+ name + "_q.fa"
                                        out_r = folder+ name + "_r.fa"
                                        alignfile = folder+name + "_o.txt"

                                        textlen = 0
                                        if os.path.isfile(alignfile) and os.stat(alignfile).st_size > 10 and os.path.isfile(out_q):
                                                with open(out_q, mode = 'r') as f2:
                                                        textlen = sum([len(x) for x in f2.read().splitlines()[1:]] + [0])


                                        if "_h" in name and "NC_0609" not in name and "chr" not in name:
                                                haplo = "_".join(name.split("_")[-3:-1])

                                                queryfile = queries[haplo]

                                        else:
                                                queryfile = params.bothref

                                        shell("samtools faidx {} {}:{}-{} {} > {} ".format(queryfile, q_c,q_s,q_e,stdflag[q_t], out_q))
                                        shell("samtools faidx {} {}:{}-{} {} > {} ".format(params.bothref, r_c,r_s,r_e,stdflag[r_t], out_r))

                                        textlen2 = 1000
                                        if textlen:
                                                with open(out_q, mode = 'r') as f2:
                                                        textlen2 = sum([len(x) for x in f2.read().splitlines()[1:]] + [0])

                                        if abs(textlen - textlen2) > 100:
                                                shell ("echo  {out_q}  >> {wildcards.prefix}_stretcherfiles")
                                                runsize += 1

                        if runsize:
                                shell("cat {}_stretcherfiles  | xargs -P {} -I [] bash -c 'name=$(echo [] | rev | cut -d_ -f2- | rev); rfile=$name\"_r.fa\"; ofile=$name\"_o.txt\"; stretcher [] $rfile  -snucleotide2  -gapopen 16  -gapextend 4  $ofile ' ".format(wildcards.prefix, threads))

rule precisealign2:
        input:  
                rawloc=ancient("{prefix}_uncertain.fa_rawloc.txt"),
        params: 
                qpath = QueryPath,
                script = ScriptFolder,
                bothref = BOTHREF,
                hg38 = HG38,
                chm13 = CHM13,
        resources:  
                mem_mb=64000,
                slurm_extra="--mem=16G -c 8"
        threads: 32
        output: 
                globalalignschecker="{prefix}_uncertain.fa_liftoveralignschecker",
        run:
                shell("touch {} || true".format(output.globalalignschecker))
                run = 0
                if os.path.isfile(input.rawloc) and os.stat(input.rawloc).st_size > 10:
                        run = 1
                if run:
                        folder = "{}_liftover/".format(wildcards.prefix.split("_group")[0] + "_group" + wildcards.prefix.split("_group")[1].split("_")[0])
                        shell("mkdir {} || true".format(folder))

                        stdflag = {"+":"",'-':"-i"}

                        shell ("rm {wildcards.prefix}_stretcherfiles2 || true")

                        shell ("touch {wildcards.prefix}_stretcherfiles2 || true")

                        runsize = 0
                        with open(input.rawloc, mode = 'r') as f:

                                table = sorted(f.readlines(), key = lambda x: int(x.split()[-2]) if len(x) else 0, reverse = 1)

                        if len(table):
                                for line in table:

                                        if len(line) == 0:
                                                continue

                                        line = line.split()

                                        name,q_c,q_s,q_e,q_t,r_c,r_s,r_e,r_t = line[:9]

                                        out_q = folder+ name + "_q.fa"
                                        out_r = folder+ name + "_r.fa"
                                        alignfile = folder+name + "_o.txt"

                                        textlen = 0
                                        if os.path.isfile(alignfile) and os.stat(alignfile).st_size > 10 and os.path.isfile(out_q):
                                                with open(out_q, mode = 'r') as f2:
                                                        textlen = sum([len(x) for x in f2.read().splitlines()[1:]] + [0])


                                        if "_h" in name and "NC_0609" not in name and "chr" not in name:
                                                haplo = "_".join(name.split("_")[-3:-1])

                                                queryfile = queries[haplo]

                                        else:
                                                queryfile = params.bothref

                                        shell("samtools faidx {} {}:{}-{} {} > {} ".format(queryfile, q_c,q_s,q_e,stdflag[q_t], out_q))
                                        shell("samtools faidx {} {}:{}-{} {} > {} ".format(params.bothref, r_c,r_s,r_e,stdflag[r_t], out_r))

                                        textlen2 = 1000
                                        if textlen:
                                                with open(out_q, mode = 'r') as f2:
                                                        textlen2 = sum([len(x) for x in f2.read().splitlines()[1:]] + [0])

                                        if abs(textlen - textlen2) > 10:
                                                shell ("echo  {out_q}  >> {wildcards.prefix}_stretcherfiles2")
                                                runsize += 1

                        if runsize:
                                shell("cat {}_stretcherfiles2  | xargs -P {} -I [] bash -c 'name=$(echo [] | rev | cut -d_ -f2- | rev); rfile=$name\"_r.fa\"; ofile=$name\"_o.txt\"; stretcher [] $rfile  -snucleotide2  -gapopen 16  -gapextend 4  $ofile ' ".format(wildcards.prefix, threads))




rule preciseloc:
        input:  
                rawloc=ancient("{prefix}_annotate.fa_rawloc.txt"),
                globalchecker=ancient("{prefix}_annotate.fa_globalalignschecker"),
                strdcorr = ancient("{prefix}_annotate.fa_novel.fa"),
        params: 
                refchm13 = RefCHM13,
                refgene= RefGenes,
                qpath = QueryPath,
                script = ScriptFolder,
                bothref = BOTHREF,
                hg38 = HG38,
                chm13 = CHM13,
        resources:  
                mem_mb=2000,
                slurm_extra="--mem=2G -c 1"
        threads: 1
        output: 
                prelocs="{prefix}_annotate.fa_prelocs.txt",
        run:
                strecherresults = wildcards.prefix+"_allstrechers.txt"
                shell("rm {} || true".format(strecherresults))
                shell("touch {output.prelocs} || true")
                run = 0
                if os.path.isfile(input.rawloc) and os.stat(input.rawloc).st_size > 10:
                        run = 1
                if run: 
                        folder = "{}_liftover/".format(wildcards.prefix.split("_group")[0] + "_group" + wildcards.prefix.split("_group")[1].split("_")[0])
                        shell("touch {strecherresults} || true")
                        shell(" ( ls {}/*_o.txt || true )  | xargs -P {} -I [] bash -c ' python {}/StretcherReader.py -i [] >> {}' ".format(folder, threads,params.script,strecherresults))

                        print("python {}/getprecisemap.py -r {} -a {} -q {} -o {} ".format(params.script, input.rawloc, strecherresults, input.strdcorr, output.prelocs))
                        shell("python {}/getprecisemap.py -r {} -a {} -q {} -o {} ".format(params.script, input.rawloc, strecherresults, input.strdcorr, output.prelocs))
                        #shell("python {}/addrefgenes.py -g {},{} -i {} -o {} ".format(params.script, params.refgene,params.refchm13,output.prelocs,  output.reflocs))


rule preciseloc2:
        input:  
                rawloc=ancient("{prefix}_uncertain.fa_rawloc.txt"),
                globalchecker=ancient("{prefix}_uncertain.fa_liftoveralignschecker"),
                strdcorr = ancient("{prefix}_uncertain.fa"),
        params: 
                refchm13 = RefCHM13,
                refgene= RefGenes,
                qpath = QueryPath,
                script = ScriptFolder,
                bothref = BOTHREF,
                hg38 = HG38,
                chm13 = CHM13,
        resources:  
                mem_mb=2000,
                slurm_extra="--mem=2G -c 1"
        threads: 1
        output: 
                prelocs="{prefix}_uncertain.fa_prelocs.txt",
        run:
                strecherresults = wildcards.prefix+"_allstrechers2.txt"

                shell("rm {} || true".format(strecherresults))
                shell("touch {output.prelocs} || true")
                run = 0
                if os.path.isfile(input.rawloc) and os.stat(input.rawloc).st_size > 10:
                        run = 1
                if run: 
                        folder = "{}_liftover/".format("_".join(wildcards.prefix.split("_")[:2]))
                        shell("touch {strecherresults} || true")
                        shell(" ( ls {}/*_o.txt || true )  | xargs -P {} -I [] bash -c ' python {}/StretcherReader.py -i [] >> {}' ".format(folder, threads,params.script, strecherresults))
                        shell("python {}/getprecisemap.py -r {} -a {} -q {} -o {} ".format(params.script, input.rawloc, strecherresults, input.strdcorr, output.prelocs))
                        #shell("python {}/addrefgenes.py -g {},{} -i {} -o {} ".format(params.script, params.refgene,params.refchm13,output.prelocs,  output.reflocs))


rule liftsummary:
        input:  
                fastafile = ancient("{prefix}_annotate.fa"),
                filterfile = ancient("{prefix}_annotate.fa_novel.fa"),
                prelocs=ancient("{prefix}_annotate.fa_prelocs.txt"),
        params: 
                refchm13 = RefCHM13,
                refgene= RefGenes,
                qpath = QueryPath,
                script = ScriptFolder,
                bothref = BOTHREF,
                hg38 = HG38,
                chm13 = CHM13,
        resources:  
                mem_mb=2000,
                slurm_extra="--mem=2G -c 1"
        threads: 1
        output: 
                summary="{prefix}_annotate.fa_liftover.txt",
        run:
                shell("touch {output.summary} || true")
                run = 0
                if os.path.isfile(input.filterfile) and os.stat(input.filterfile).st_size > 10:
                        run = 1
                if run:
                        import collections as cl
                        import re
                        allsamples = dict()
                        with open(input.filterfile, mode = 'r') as f:
                                for line in f:
                                        if len(line) and line[0] == '>':
                                                allsamples[line.split()[0][1:]] = line.split()[1]
                        ifexons =  cl.defaultdict(int)
                        refsamples = cl.defaultdict(list)
                        with open(input.fastafile, mode = 'r') as f:
                                for line in f:
                                        if len(line) and line[0] == '>':

                                                if "_h" not in line.split()[0]:

                                                        region = line.split()[1][:-1]
                                                        chrom = region.split(":")[0]
                                                        start = int(region.split(":")[1].split('-')[0])
                                                        end = int(region.split(":")[1].split('-')[1])

                                                        refsamples[chrom].append( [start, end, line.split()[0][1:]] )

                                                if "ENSE" in line.split()[-1]:
                                                        ifexons[line.split()[0][1:]] = 1


                        outlines = dict()
                        with open(input.prelocs, mode = 'r') as f:
                                for line in f:
                                        line = line.split()
                                        refalign = "{}:{}-{}{}".format(line[6], line[8],line[9],line[7])

                                        overlapref = [x for x in refsamples.get(line[6], []) if  int(line[9]) - int(line[8]) + int(x[1]) - int(x[0]) > max(int(x[1]), int(line[9])) - min(int(x[0]),int(line[8])) ]

                                        findref = "NA"
                                        if len(overlapref):
                                                findref = overlapref[0][2]
                                                cigar = line[17]
                                                insertsize = sum ([int(x[:-1]) for x in re.findall('\d+I',cigar)]) 

                                                if insertsize < 0.5 * int(line[5]):
                                                        thekind = "Mutate"
                                                else:
                                                        thekind = "Novel(insert)"
                                        else:
                                                thekind = "Novel(trans)"

                                        outlines[line[0]] = [line[0], findref, allsamples[line[0]], refalign, str(ifexons[line[0]])  ,"1.0" ,thekind]

                        for allele,locus in allsamples.items():

                                if allele not in outlines:

                                        outlines[allele] = [allele, "NA", locus, "NA",  str(ifexons[line[0]]) ,"1.0" ,"Novel(unmap)"]

                        with open(output.summary, mode = 'w') as f:
                                f.write("\n".join(["\t".join(x) for x in outlines.values()]) + "\n")


rule liftsummary2:
        input:  
                fastafile = ancient("{prefix}_annotate.fa"),
                filterfile = ancient("{prefix}_uncertain.fa"),
                prelocs=ancient("{prefix}_uncertain.fa_prelocs.txt"),
        params: 
                refchm13 = RefCHM13,
                refgene= RefGenes,
                qpath = QueryPath,
                script = ScriptFolder,
                bothref = BOTHREF,
                hg38 = HG38,
                chm13 = CHM13,
        resources:  
                mem_mb=2000,
                slurm_extra="--mem=2G -c 1"
        threads: 1
        output: 
                summary="{prefix}_uncertain.fa_liftover.txt",
        run:
                shell("touch {output.summary} || true")
                run = 0
                if os.path.isfile(input.filterfile) and os.stat(input.filterfile).st_size > 10:
                        run = 1
                if run:
                        import collections as cl
                        import re
                        allsamples = dict()
                        with open(input.filterfile, mode = 'r') as f:
                                for line in f:
                                        if len(line) and line[0] == '>':
                                                allsamples[line.split()[0][1:]] = line.split()[1]
                        ifexons =  cl.defaultdict(int)
                        refsamples = cl.defaultdict(list)
                        with open(input.fastafile, mode = 'r') as f:
                                for line in f:
                                        if len(line) and line[0] == '>':

                                                if "_h" not in line.split()[0]:

                                                        region = line.split()[1][:-1]
                                                        chrom = region.split(":")[0]
                                                        start = int(region.split(":")[1].split('-')[0])
                                                        end = int(region.split(":")[1].split('-')[1])

                                                        refsamples[chrom].append( [start, end, line.split()[0][1:]] )

                                                if "ENSE" in line.split()[-1]:
                                                        ifexons[line.split()[0][1:]] = 1


                        outlines = dict()
                        with open(input.prelocs, mode = 'r') as f:
                                for line in f:
                                        line = line.split()
                                        refalign = "{}:{}-{}{}".format(line[6], line[8],line[9],line[7])

                                        overlapref = [x for x in refsamples.get(line[6], []) if  int(line[9]) - int(line[8]) + int(x[1]) - int(x[0]) > max(int(x[1]), int(line[9])) - min(int(x[0]),int(line[8])) ]

                                        findref = "NA"
                                        if len(overlapref):
                                                findref = overlapref[0][2]
                                                cigar = line[17]
                                                insertsize = sum ([int(x[:-1]) for x in re.findall('\d+I',cigar)]) 

                                                if insertsize < 0.5 * int(line[5]):
                                                        thekind = "Mutate"
                                                else:
                                                        thekind = "Novel(insert)"
                                        else:
                                                thekind = "Novel(trans)"

                                        outlines[line[0]] = [line[0], findref, allsamples[line[0]], refalign, str(ifexons[line[0]])  ,"1.0" ,thekind]

                        for allele,locus in allsamples.items():

                                if allele not in outlines:

                                        outlines[allele] = [allele, "NA", locus, "NA",  str(ifexons[line[0]]) ,"1.0" ,"Novel(unmap)"]

                        with open(output.summary, mode = 'w') as f:
                                f.write("\n".join(["\t".join(x) for x in outlines.values()]) + "\n")




#variants call begin

rule globalalign:
        input:
                refmatch=ancient("{prefix}_annotate.fa_refmatch"),
        params: 
                qpath = QueryPath,
                script = ScriptFolder,
                bothref = BOTHREF,
                hg38 = HG38,
                chm13 = CHM13,
                anchor = 100,
                slurm=slurm,
        resources:
                mem_mb=128000,
                slurm_extra="--mem=128G -c 64"
        threads: 64
        output: 
                globalalignschecker="{prefix}_annotate.fa_globalalignschecker",
        run:
                shell("touch {} || true".format(output.globalalignschecker))
                run = 1
                if run:
                        folder = "{}_stretchers/".format(wildcards.prefix.split("_group")[0] + "_group" + wildcards.prefix.split("_group")[1].split("_")[0])
                        shell("mkdir {} || true".format(folder))

                        stdflag = {"+":"",'-':"-i"}

                        shell ("rm {wildcards.prefix}_stretcherfiles || true")

                        shell ("touch {wildcards.prefix}_stretcherfiles || true")

                        runsize = 0
                        with open(input.refmatch, mode = 'r') as f:

                                table = f.readlines()

                        if len(table):
                                for line in table:

                                        if len(line) == 0:
                                                continue

                                        line = line.split('\t')

                                        #name,q_c,q_s,q_e,q_t,r_c,r_s,r_e,r_t = line[:9]
                                        qname,rname,qregion,rregion = line[:4]
                                        if rname == "NA":
                                                continue

                                        q_c, qcord  = qregion.split(":")
                                        q_t = qcord[-1]
                                        q_s,q_e = qcord[:-1].split('-')
                                        q_s,q_e = max(0, int(q_s) - params.anchor), int(q_e) + params.anchor

                                        r_c, rcord  = rregion.split(":")
                                        r_t = rcord[-1]
                                        r_s,r_e = rcord[:-1].split('-')
                                        r_s,r_e = max(0, int(r_s) - params.anchor), int(r_e) + params.anchor

                                        out_q = folder+ qname + "_q.fa"
                                        out_r = folder+ qname + "_r.fa"
                                        alignfile = folder+ qname + "_o.txt"


                                        if "_h" in qname and "NC_0609" not in qname and "chr" not in qname:
                                                haplo = "_".join(qname.split("_")[-3:-1])
                                                queryfile = queries[haplo]

                                        else:   
                                                queryfile = params.bothref

                                        shell("samtools faidx {} {}:{}-{} {} > {} ".format(queryfile, q_c,q_s,q_e,stdflag[q_t], out_q))
                                        shell("samtools faidx {} {}:{}-{} {} > {} ".format(params.bothref, r_c,r_s,r_e,stdflag[r_t], out_r))

                                        shell ("echo  {out_q}  >> {wildcards.prefix}_stretcherfiles")

                        shell("cat {}_stretcherfiles  | xargs -P {} -I [] bash -c 'name=$(echo [] | rev | cut -d_ -f2- | rev); rfile=$name\"_r.fa\"; ofile=$name\"_o.txt\"; stretcher [] $rfile  -snucleotide2  -gapopen 16  -gapextend 4  $ofile ' ".format(wildcards.prefix, threads))


rule SVcalling:
        input:  
                refmatch = "{prefix}_annotate.fa_globalalignschecker",
        params:
                refgenes = RefGenes,
                qpath = QueryPath,
                script = ScriptFolder,
                hg38 = HG38,
                AlignFolder = AlignmentsFolder
        resources:
                mem_mb=8000,
                slurm_extra="--mem=8G -c 4"
        threads: 4
        output: 
                svfile = "{prefix}_annotate.fa_svcall.tsv",
        run:
                run = 1
                if run:
                        folder = "{}_stretchers/".format(wildcards.prefix.split("_group")[0] + "_group" + wildcards.prefix.split("_group")[1].split("_")[0])
                        allfiles = [folder+x for x in os.listdir(folder) if x.endswith("_o.txt")]
                        tempfile = output.svfile + "_temp"

                        shell ("> " + output.svfile)

                        for afile in allfiles:

                                shell (" python {}/strdcheck.py -i {} ".format(params.script, afile))
                                shell (" python {}/PairwiseAnnotation.py -i {} -o {} ".format(params.script, afile, tempfile))

                                thename = "_".join(afile.split("/")[-1].split('_')[2:-1])
                                if thename.startswith("NC_0609"):
                                        haplotype = "CHM13_h1"

                                elif thename.startswith("chr") == False and "v" not in thename.split("#")[0]:
                                        haplotype = "_".join(thename.split('_')[:2])

                                else:   
                                        haplotype = "HG38_h1"

                                shell (  "awk -v OFS=\"\t\"   \'{{{{print \"{}\", $0}}}}\' {} >> {}".format(thename,tempfile,output.svfile) )

rule SVcalling2:
        input:  
                prelocs=ancient("{prefix}_annotate.fa_prelocs.txt"),
        params: 
                refchm13 = RefCHM13,
                refgene= RefGenes,
                qpath = QueryPath,
                script = ScriptFolder,
                bothref = BOTHREF,
                hg38 = HG38,
                chm13 = CHM13,
        resources:  
                mem_mb=2000,
                slurm_extra="--mem=2G -c 1"
        output: 
                svfile = "{prefix}_annotate.fa_svcall2.tsv",
        threads: 1
        run:
                shell("touch {} || true".format(output.svfile))
                run = 0
                if os.path.isfile(input.prelocs) and os.stat(input.prelocs).st_size > 10:
                        run = 1
                if run:
                        folder = "{}_stretchers/".format(wildcards.prefix.split("_group")[0] + "_group" + wildcards.prefix.split("_group")[1].split("_")[0])
                        shell("mkdir {} || true".format(folder))
                        shell("> {output.svfile}") 
                        tempfile = output.svfile + "_temp"
                        stdflag = {"+":"",'-':"-i"}
                        with open(input.prelocs, mode = 'r') as f:
                                for line in f:
                                        if len(line.strip().split() ) < 10:
                                                                        continue
                                        name,q_c,q_t,q_s,q_e,q_size, r_c,r_t,r_s,r_e,r_size = line.split()[:11]

                        if int(r_s) - int(r_e) <= 0:
                                r_s =max(0, int(r_s) - 10)
                                r_e =int(r_e)+ 10

                                out_q = folder+ name + "_q.fa"
                                out_r = folder+ name + "_r.fa"
                                alignfile = folder+name + "_o.txt"

                                if "_h" in name and "NC_0609" not in name and "chr" not in name:
                                                haplo = "_".join(name.split("_")[-3:-1])

                                                queryfile = queries[haplo]

                                else:
                                                queryfile = params.bothref

                                shell("samtools faidx {} {}:{}-{} {} > {} ".format(queryfile, q_c,q_s,q_e,stdflag[q_t], out_q))
                                shell("samtools faidx {} {}:{}-{} {} > {} ".format(params.bothref, r_c,r_s,r_e,stdflag[r_t], out_r))

                                shell("stretcher {} {}  -snucleotide2  -gapopen 16  -gapextend 4  {} ".format(out_q, out_r, alignfile))

                                shell ("python {}/strdcheck.py -i {} ".format(params.script, alignfile))

                                shell (" python {}/PairwiseAnnotation.py -i {} -o {} ".format(params.script,  alignfile, tempfile))

                                shell (  "awk -v OFS=\"\t\"   \'{{{{print \"{}\", $0}}}}\' {} >> {}".format(name,tempfile,output.svfile) )



rule uniqvar:
        input:  
                refmatch=ancient("{prefix}_annotate.fa_refmatch"),
                svfile = "{prefix}_annotate.fa_svcall.tsv",
                anchorfile = "{prefix}_annotate.fa",
        params: 
                refchm13 = RefCHM13,
                refgene= RefGenes,
                qpath = QueryPath,
                script = ScriptFolder,
                bothref = BOTHREF,
                hg38 = HG38,
                chm13 = CHM13,
        resources:  
                mem_mb=2000,
                slurm_extra="--mem=2G -c 1"
        output: 
                svfile2 = "{prefix}_annotate.fa_svcalluniq.tsv",
        threads: 1
        run:
                def getreads(filepath):

                        with open(filepath, mode = 'r') as f:
                                reads = [x.splitlines() for x in f.read().split(">")[1:]]
                                reads = {read[0].split()[0]:"".join(read[1:]) for read in reads}

                        return reads

                folder = "{}_stretchers/".format(wildcards.prefix.split("_group")[0] + "_group" + wildcards.prefix.split("_group")[1].split("_")[0])

                run = 1 
                if run:
                        prefix = "_".join(wildcards.prefix.split("/")[-1].split("_")[:2])+"_"   
                        results = []
                        reads = getreads(input.anchorfile)

                        liftinfo = dict()
                        with open(input.refmatch, mode = 'r') as f:
                                for line in f:
                                        line = line.strip().split()
                                        liftinfo[line[0]] = line[1]

                        with open(input.svfile, mode = 'r') as f:

                                for line_ in f:

                                        line = line_.strip().split()

                                        if len(line) < 6:
                                                results.append(prefix+line_[:-1])
                                                continue

                                        qseq = reads[prefix + line[0]]
                                        rseq = reads[liftinfo[prefix + line[0]]]

                                        thetype = line[2]

                                        SVseq = ""
                                        if thetype in ["Insertion","Duplication"]:

                                                SVseq = qseq[int(line[3]):int(line[4])]

                                        elif thetype in ["Deletion","Contraction"]:

                                                SVseq = rseq[int(line[5]):int(line[6])]

                                        uniquesize = len([char for char in SVseq if char.isupper()])

                                        results.append(prefix+line_[:-1] + "\t"+str(uniquesize))

                        with open(output.svfile2, mode = 'w') as f:

                                f.write("\n".join(results)+"\n")


rule uniqvar2:
        input:  
                svfile = "{prefix}_annotate.fa_svcall2.tsv",
                groupfile = "{prefix}_annotate.fa",
        params: 
                refchm13 = RefCHM13,
                refgene= RefGenes,
                qpath = QueryPath,
                script = ScriptFolder,
                bothref = BOTHREF,
                hg38 = HG38,
                chm13 = CHM13,
        resources:  
                mem_mb=2000,
                slurm_extra="--mem=10G -c 1"
        output: 
                svfile2 = "{prefix}_annotate.fa_svcalluniq2.tsv",
        threads: 1
        run:
                def getread(filepath, name):

                        seq = ""
                        startread = 0
                        with open( filepath, mode = 'r') as f:
                                for aline in f:
                                        if len(aline) and aline[0] == ">":
                                                if startread:
                                                        break
                                                elif aline.startswith(">"+name):
                                                        startread = 1

                                        elif startread:

                                                seq += aline.strip()

                        return seq


                folder = "{}_stretchers/".format(wildcards.prefix.split("_group")[0] + "_group" + wildcards.prefix.split("_group")[1].split("_")[0])
                shell("touch {} || true".format(output.svfile2))
                run = 0
                if os.path.isfile(input.svfile) and os.stat(input.svfile).st_size > 10:
                        run = 1 

                if run:
                        results = []
                        with open(input.svfile, mode = 'r') as f:

                                for line_ in f:

                                        line = line_.strip().split()

                                        if len(line) < 6:
                                                results.append(line_[:-1])
                                                continue

                                        qseq = getread(input.groupfile, line[0])
                                        out_r = folder+ line[0] + "_r.fa"

                                        with open(out_r, mode = 'r') as f:
                                                read = f.readline()
                                                rseq = f.read().replace("\n","")

                                        thetype = line[2]

                                        SVseq = ""
                                        if thetype in ["Insertion","Duplication"]:

                                                SVseq = qseq[int(line[3]):int(line[4])]

                                        elif thetype in ["Deletion","Contraction"]:

                                                SVseq = rseq[int(line[5]):int(line[6])]

                                        uniquesize = len([char for char in SVseq if char.isupper()])

                                        results.append(line_[:-1] + "\t"+str(uniquesize))

                        with open(output.svfile2, mode = 'w') as f:

                                f.write("\n".join(results))


rule exonlocation:
        input:  
                fasta = "{prefix}_annotate.fa",
        params:
                refgenes = RefGenes,
                qpath = QueryPath,
                script = ScriptFolder,
                hg38 = HG38,
                AlignFolder = AlignmentsFolder
        resources:
                mem_mb=2000,
                slurm_extra="--mem=2G -c 1"
        threads: 1
        output: 
                genecount = "{prefix}_annotate.fa_exons.tsv",
        run:
                run=1
                if run:
                        outfile = output.genecount

                        shell ("> " + outfile)

                        genename = wildcards.prefix.split("/")[-1].split('_')[0]

                        alignfilepath = "{}/{}/{}_hotspots".format(params.AlignFolder, genename, genename)

                        loci = dict()
                        with open(input.fasta, mode = 'r') as f:

                                for line in f:

                                        if line.startswith(">"):

                                                thename, locus = line[1:].split()[:2]
                                                loci[thename] = locus

                        for thename, locus in loci.items():

                                if locus.startswith("NC_0609"):
                                        haplotype = "CHM13_h1"

                                elif locus.startswith("chr") == False and "v" not in locus.split("#")[0]:
                                        haplotype = "_h".join(locus.split('#')[:2])

                                else:   
                                        haplotype = "HG38_h1"

                                thefile = "{}/{}_hotspot.txt.fa.paf".format(alignfilepath, haplotype)

                                shell (" python {}/FindingExons.py -i {}  -r {} -o {}_temp ".format(params.script, thefile,  locus[:-1], outfile))

                                shell (  "awk -v OFS=\"\t\"   \'{{{{print \"{}\", $0}}}}\' {}_temp >> {}".format(thename,outfile,outfile) )




rule genecount:
        input:  
                refmatch = "{prefix}_annotate.fa_refmatch",
                liftover = "{prefix}_annotate.fa_liftover.txt",
        params:
                refgenes = RefGenes,
                qpath = QueryPath,
                script = ScriptFolder,
                hg38 = HG38,
                AlignFolder = AlignmentsFolder
        resources:
                mem_mb=5000,
                slurm_extra="--mem=5G -c 1"
        threads: 1
        output: 
                genecount = "{prefix}_annotate.fa_genecounts.tsv",
        run:
                run=1
                if run:
                        outfile = output.genecount

                        shell ("> " + outfile)

                        genename = wildcards.prefix.split("/")[-1].split('_')[0]

                        gff3file = "{}/{}/{}.gff3".format(params.AlignFolder, genename,genename)


                        alignfilepath = "{}/{}/{}_hotspots".format(params.AlignFolder, genename, genename)

                        loci = dict()
                        allheaders = []
                        with open(input.refmatch, mode = 'r') as f:

                                for line in f:

                                        if len(line):
                                                line = line.split()
                                                loci[line[0]] = [line[2][:-1],line[2][:-1]]

                        with open(input.refmatch, mode = 'r') as f:

                                for line in f:

                                        if len(line):
                                                line = line.split()
                                                if line[1] != "NA":
                                                        loci[line[0]][1] =  loci[line[1]][0]

                        with open(input.liftover, mode = 'r') as f:

                                for line in f:

                                        if len(line):
                                                line = line.split()
                                                if line[1] != "NA":
                                                        loci[line[0]][1] =  loci[line[1]][0]


                        for thename, (locus, refloc) in loci.items():

                                if locus.startswith("NC_0609"):
                                        haplotype = "CHM13_h1"

                                elif locus.startswith("chr") == False and "v" not in locus.split("#")[0]:
                                        haplotype = "_h".join(locus.split('#')[:2])

                                else:   
                                        haplotype = "HG38_h1"

                                        refloc = locus

                                thefile = "{}/{}_hotspot.txt.fa.paf".format(alignfilepath, haplotype)

                                if refloc != "NA":
                                        shell (" python {}/CountingGenes.py -i {} -g {} -r {} -t {} -o {}_temp ".format(params.script, thefile, gff3file, locus, refloc, outfile))
                                else:
                                        shell (" python {}/CountingGenes.py -i {} -g {} -r {} -o {}_temp ".format(params.script, thefile, gff3file, locus, outfile))

                                shell (  "awk -v OFS=\"\t\"   \'{{{{print \"{}\", $0}}}}\' {}_temp >> {}".format(thename,outfile,outfile) )


rule annotatesummary:
        input:
                fasta = "{prefix}_annotate.fa",
                refmatch = "{prefix}_annotate.fa_refmatch",
                liftover = "{prefix}_annotate.fa_liftover.txt",
                liftover2 = "{prefix}_uncertain.fa_liftover.txt",
                genecount = ancient("{prefix}_annotate.fa_genecounts.tsv"),
                types = "{prefix}_annotate.fa_types.txt",
                graphfile = "{prefix}_annotate.fa_lineargraph.gaf",
                svfile = "{prefix}_annotate.fa_svcalluniq.tsv",
                svfile2 = "{prefix}_annotate.fa_svcalluniq2.tsv",
                exons = "{prefix}_annotate.fa_exons.tsv",
                infofile = "{prefix}_filter.fa_info",
        params:
                refgenes = RefGenes,
                qpath = QueryPath,
                script = ScriptFolder,
                hg38 = HG38,
                AlignFolder = AlignmentsFolder
        resources:
                mem_mb=5000,
                slurm_extra="--mem=5G -c 1 "
        threads: 1
        output:
                summary = "{prefix}_annotate.fa_annotatesummary.txt",
        run:
                genename = wildcards.prefix.split("/")[-1].split('_')[0]

                gff3file = "{}/{}/{}.gff3".format(params.AlignFolder, genename,genename)
                folder = SaveFolder + "_".join(wildcards.prefix.split("/")[-1].split('_')[:2]) + "_stretchers/"
                shell("python {params.script}/SummaryAnnotate.py -i {input.fasta} -t {input.types}  -r {input.refmatch} -l1 {input.liftover} -l2 {input.liftover2}  -g {input.graphfile} -c {input.genecount} -s {input.svfile} -s2 {input.svfile2} -f {folder} -k {input.infofile} -e  {input.exons} -d {params.refgenes} -gff {gff3file} -ref {params.hg38} -o {output.summary}")



rule summaryfix:
        input:  
                summary = "{prefix}_annotate.fa_annotatesummary.txt",
        params: 
                refgenes = RefGenes,
                qpath = QueryPath,
                script = ScriptFolder,
                hg38 = HG38
        resources:
                mem_mb=5000,
                slurm_extra="--mem=5G -c 1 "
        threads: 1
        output: 
                summaryfix = "{prefix}_annotate.fa_annotatefix.txt",
                summaryfixed = "{prefix}_annotate.fa_annotatesummaryfix.txt",
        run:
                prefix = wildcards.prefix
                normfile = wildcards.prefix + "_annotate.fa_norm.txt"

                shell (" python {params.script}/fixtruncate.py -i {input.summary} -n {normfile} -o {output.summaryfix} ")

                line_fix = []
                with open(output.summaryfix, mode = 'r') as f:

                        for line in f:

                                line_fix.append(line.strip().split('\t'))


                table = []
                with open(input.summary, mode = 'r') as f:

                        index = 0
                        for line in f:

                                row = line.split('\t')
                                fix = line_fix[index]

                                if fix[1] != "NA":

                                        row[1] += ":{}".format(fix[3].split("&")[0])

                                if fix[4] != row[8] and fix[4]!="NA" and len(fix[4]) and row[8] in fix[4].split(";"):
                                        row[8] += "({}".format(fix[4])

                                if fix[-1] != row[2] and row[2]!="NA" and len(row[2]):
                                        row[2] += ":{}".format(fix[-1])

                                table.append("\t".join(row))
                                index += 1

                with open(output.summaryfixed, mode = 'w') as f:

                        f.write("".join(table))



rule typing:
        input:
                fasta = "{prefix}_annotate.fa",
                genecount = "{prefix}_annotate.fa_genecounts.tsv",
        params:
                qpath = QueryPath,
                script = ScriptFolder,
                hg38 = HG38
        resources:
                mem_mb=10000,
                slurm_extra="--mem=10G -c 1 "
        threads: 1
        output:
                typefile = "{prefix}_annotate.fa_types.txt",
        run:
                shell ("python {params.script}/TreeClassify.py -i {input.fasta} -g {input.genecount}  -o {output.typefile} ")




rule typesummary:
        input:
                summary = "{prefix}_annotate.fa_annotatesummaryfix.txt",
        params:
                refgenes = RefGenes,
                qpath = QueryPath,
                script = ScriptFolder,
                hg38 = HG38
        resources:
                mem_mb=5000,
                slurm_extra="--mem=5G -c 1 "
        threads: 1
        output:
                typeannotate = "{prefix}_annotate.fa_typeannotate.txt",
        run:
                prefix = wildcards.prefix.split("/")[-1][:3]
                shell (" python {params.script}/SummaryTypes.py -i {input.summary} -o {output.typeannotate} ")


rule MSAfromGraph:
        input:  
                lineargraph = "{prefix}_annotate.fa_lineargraph.gaf",
        params:
                refgenes = RefGenes,
                qpath = QueryPath,
                script = ScriptFolder,
                hg38 = HG38,
                AlignFolder = AlignmentsFolder
        resources:
                mem_mb=64000,
                slurm_extra="--mem=64G -c 1"
        threads: 1
        output: 
                MSAfile = "{prefix}_annotate.fa_msa.fa",
        run:
                run = 1
                if run:
                        shell (" python {}/mutanttoMSA.py -i {} -o {}".format(params.script, input.lineargraph,output.MSAfile))
